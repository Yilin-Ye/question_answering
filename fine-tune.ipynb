{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38672a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from transformers import TapasTokenizer, TapasConfig, TapasForQuestionAnswering, AdamW\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b00590",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the designed question dataset \n",
    "data = pd.read_csv('question.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "data['answer_coordinates'] = data['answer_coordinates'].apply(lambda coords_str: literal_eval(coords_str))\n",
    "data['answer_text'] = data['answer_text'].apply(lambda txt: literal_eval(txt))\n",
    "data['float_answer'] = data['float_answer'].apply(lambda x: [[float(x)]] if isinstance(x,str) else [[x]])\n",
    "data['question'] = data['question'].apply(lambda question: literal_eval(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the batch size = 6 based on my own gpu memory. RTX2070\n",
    "\n",
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = data.iloc[idx]\n",
    "        table = pd.read_csv(item.table_file).astype(str)  \n",
    "        encoding = self.tokenizer(\n",
    "            table=table,\n",
    "            queries=item.question,\n",
    "            answer_coordinates=item.answer_coordinates,\n",
    "            answer_text=item.answer_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        encoding[\"float_answer\"] = torch.tensor(item.float_answer)\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "train_dataset = TableDataset(data, tokenizer)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4db558",
   "metadata": {},
   "source": [
    "### start to fine-tune this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221677ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the default WTQ configuration\n",
    "config = TapasConfig(\n",
    "    num_aggregation_labels=4,\n",
    "    use_answer_as_supervision=True,\n",
    "    answer_loss_cutoff=0.664694,\n",
    "    cell_selection_preference=0.207951,\n",
    "    huber_loss_delta=0.121194,\n",
    "    init_cell_selection_weights_to_zero=True,\n",
    "    select_one_column=True,\n",
    "    allow_empty_column_selection=False,\n",
    "    temperature=0.0352513,\n",
    ")\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "\n",
    "start = time.time() \n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for batch in train_dataloader:\n",
    "        # get the inputs;\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        numeric_values = batch[\"numeric_values\"].to(device)\n",
    "        numeric_values_scale = batch[\"numeric_values_scale\"].to(device)\n",
    "        float_answer = batch[\"float_answer\"].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels,\n",
    "            numeric_values=numeric_values,\n",
    "            numeric_values_scale=numeric_values_scale,\n",
    "            float_answer=float_answer,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        print(\"Loss:\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time elapsed: {(end-start)/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671bbb5",
   "metadata": {},
   "source": [
    "### save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_model = 'models/fine_tuned.pth'\n",
    "\n",
    "# save\n",
    "def save(model, optimizer):\n",
    "    # save\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, output_model)\n",
    "\n",
    "save(model, optimizer)\n",
    "\n",
    "# load\n",
    "#checkpoint = torch.load(output_model, map_location='cpu')\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0c012",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def compute_prediction_sequence(model, data, device):\n",
    "  \n",
    "  # prepare data\n",
    "    input_ids = data[\"input_ids\"].to(device)\n",
    "    attention_mask = data[\"attention_mask\"].to(device)\n",
    "    token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "    all_logits = []\n",
    "    prev_answers = None\n",
    "\n",
    "    num_batch = data[\"input_ids\"].shape[0]\n",
    "\n",
    "    for idx in range(num_batch):\n",
    "\n",
    "        if prev_answers is not None:\n",
    "            coords_to_answer = prev_answers[idx]\n",
    "            prev_label_ids_example = token_type_ids_example[:,3] \n",
    "            model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) \n",
    "\n",
    "   \n",
    "            token_type_ids_example = token_type_ids[idx]\n",
    "            for i in range(model_label_ids.shape[0]):\n",
    "                segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "                col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "                row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "                if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
    "                    model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
    "\n",
    " \n",
    "            token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)   \n",
    "\n",
    "    prev_answers = {}\n",
    "    # get the example\n",
    "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
    "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
    "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "    # forward pass to obtain the logits\n",
    "    outputs = model(input_ids=input_ids_example.unsqueeze(0), \n",
    "                attention_mask=attention_mask_example.unsqueeze(0), \n",
    "                token_type_ids=token_type_ids_example.unsqueeze(0))\n",
    "    logits = outputs.logits\n",
    "    all_logits.append(logits)\n",
    "\n",
    "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
    "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
    "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device) \n",
    "\n",
    "    # Compute average probability per cell, aggregating over tokens.\n",
    "    # Dictionary maps coordinates to a list of one or more probabilities\n",
    "    coords_to_probs = collections.defaultdict(list)\n",
    "    prev_answers = {}\n",
    "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
    "        segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "        col = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "        row = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "        if col >= 0 and row >= 0 and segment_id == 1:\n",
    "            coords_to_probs[(col, row)].append(p)\n",
    "\n",
    "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
    "    coords_to_answer = {}\n",
    "    for key in coords_to_probs:\n",
    "        coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
    "    prev_answers[idx+1] = coords_to_answer\n",
    "\n",
    "    logits_batch = torch.cat(tuple(all_logits), 0)\n",
    "\n",
    "    return logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(table=ddd, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "logits = compute_prediction_sequence(model, inputs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55b351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
